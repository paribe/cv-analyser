import os
from openai import OpenAI

# Tentar carregar dotenv se dispon√≠vel
try:
    from dotenv import load_dotenv
    load_dotenv()
except ImportError:
    pass  # dotenv n√£o instalado, usar apenas vari√°veis de ambiente

class OpenAIClient:
    def __init__(self, api_key=None):
        """Initialize the OpenAI client"""
        # Obter API key de diferentes fontes
        if api_key:
            self.api_key = api_key
        elif os.getenv('OPENAI_API_KEY'):
            self.api_key = os.getenv('OPENAI_API_KEY')
        else:
            raise ValueError("""
            ‚ùå API key do OpenAI n√£o encontrada!
            
            Configure de uma das formas:
            1. Vari√°vel de ambiente: export OPENAI_API_KEY="sua-api-key"
            2. Arquivo .env: OPENAI_API_KEY=sua-api-key
            3. Passar diretamente: OpenAIClient(api_key="sua-api-key")
            """)
        
        try:
            self.client = OpenAI(api_key=self.api_key)
            print("‚úÖ Cliente OpenAI inicializado com sucesso!")
        except Exception as e:
            raise Exception(f"Erro ao inicializar cliente OpenAI: {str(e)}")
    
    def resume_cv(self, content):
        """Generate a resume summary from CV content"""
        try:
            if not content or content.strip() == "":
                return "Erro: Conte√∫do do curr√≠culo est√° vazio"
            
            print("üîÑ Gerando resumo do curr√≠culo...")
            response = self.client.chat.completions.create(
                model="gpt-3.5-turbo",
                messages=[
                    {
                        "role": "system", 
                        "content": "Voc√™ √© um assistente de RH profissional. Resuma o seguinte conte√∫do de curr√≠culo em portugu√™s de forma clara e objetiva, destacando as principais qualifica√ß√µes, experi√™ncias e habilidades do candidato."
                    },
                    {
                        "role": "user", 
                        "content": f"Por favor, resuma este curr√≠culo de forma profissional:\n\n{content}"
                    }
                ],
                max_tokens=500,
                temperature=0.7
            )
            
            result = response.choices[0].message.content
            print(f"‚úÖ Resumo gerado! Tokens usados: {response.usage.total_tokens}")
            return result
            
        except Exception as e:
            error_msg = f"Erro ao gerar resumo: {str(e)}"
            print(f"‚ùå {error_msg}")
            return error_msg
    
    def generate_opnion(self, content, job):
        """Generate an opinion about the CV for a specific job"""
        try:
            if not content or content.strip() == "":
                return "Erro: Conte√∫do do curr√≠culo est√° vazio"
            
            job_name = job.get('name', 'N√£o especificada')
            job_description = job.get('description', 'N√£o especificada')
            
            prompt = f"""
            Analise o seguinte curr√≠culo em rela√ß√£o √† vaga especificada:
            
            VAGA: {job_name}
            DESCRI√á√ÉO DA VAGA: {job_description}
            
            CURR√çCULO:
            {content}
            
            Forne√ßa uma an√°lise detalhada e profissional sobre:
            1. Adequa√ß√£o do candidato √† vaga
            2. Pontos fortes do candidato
            3. Poss√≠veis lacunas ou √°reas de desenvolvimento
            4. Recomenda√ß√£o geral (contratar, n√£o contratar, entrevista)
            
            Seja objetivo e construtivo na an√°lise.
            """
            
            print("üîÑ Gerando an√°lise do curr√≠culo vs vaga...")
            response = self.client.chat.completions.create(
                model="gpt-3.5-turbo",
                messages=[
                    {
                        "role": "system",
                        "content": "Voc√™ √© um especialista em RH experiente. Analise curr√≠culos em rela√ß√£o √†s vagas de forma detalhada, profissional e construtiva em portugu√™s."
                    },
                    {
                        "role": "user",
                        "content": prompt
                    }
                ],
                max_tokens=800,
                temperature=0.7
            )
            
            result = response.choices[0].message.content
            print(f"‚úÖ An√°lise gerada! Tokens usados: {response.usage.total_tokens}")
            return result
            
        except Exception as e:
            error_msg = f"Erro ao gerar an√°lise: {str(e)}"
            print(f"‚ùå {error_msg}")
            return error_msg
    
    def generate_score(self, resume, job):
        """Generate a compatibility score between resume and job"""
        try:
            if not resume or resume.strip() == "":
                return 0.0
            
            job_name = job.get('name', 'N√£o especificada')
            job_description = job.get('description', 'N√£o especificada')
            
            prompt = f"""
            Com base no resumo do curr√≠culo e na descri√ß√£o da vaga abaixo, 
            forne√ßa uma pontua√ß√£o de compatibilidade de 0 a 100:
            
            VAGA: {job_name}
            DESCRI√á√ÉO DA VAGA: {job_description}
            
            RESUMO DO CURR√çCULO:
            {resume}
            
            Crit√©rios de avalia√ß√£o:
            - Experi√™ncia relevante (30%)
            - Habilidades t√©cnicas (25%)
            - Forma√ß√£o acad√™mica (20%)
            - Adequa√ß√£o cultural/perfil (25%)
            
            Responda APENAS com o n√∫mero da pontua√ß√£o (exemplo: 75)
            """
            
            print("üîÑ Calculando score de compatibilidade...")
            response = self.client.chat.completions.create(
                model="gpt-3.5-turbo",
                messages=[
                    {
                        "role": "system",
                        "content": "Voc√™ √© um especialista em RH. Forne√ßa apenas uma pontua√ß√£o num√©rica de 0 a 100 para compatibilidade curr√≠culo-vaga."
                    },
                    {
                        "role": "user",
                        "content": prompt
                    }
                ],
                max_tokens=10,
                temperature=0.3
            )
            
            # Extract numerical score
            score_text = response.choices[0].message.content.strip()
            print(f"üéØ Score bruto recebido: '{score_text}'")
            
            try:
                # Tentar converter diretamente
                score = float(score_text)
                # Garantir que est√° no range 0-100
                final_score = max(0.0, min(100.0, score))
                print(f"‚úÖ Score final: {final_score}")
                return final_score
            except ValueError:
                # Se n√£o conseguir converter, extrair n√∫meros da resposta
                import re
                numbers = re.findall(r'\d+', score_text)
                if numbers:
                    score = float(numbers[0])
                    final_score = max(0.0, min(100.0, score))
                    print(f"‚úÖ Score extra√≠do: {final_score}")
                    return final_score
                print("‚ö†Ô∏è N√£o foi poss√≠vel extrair score, retornando 0.0")
                return 0.0
                
        except Exception as e:
            error_msg = f"Erro ao gerar pontua√ß√£o: {str(e)}"
            print(f"‚ùå {error_msg}")
            return 0.0