{"jobs": {"1": {"id": "815fd586-bfe9-4146-a80f-a97c61ac88c9", "name": "Data Engineer", "main_activities": "\nProjetar e implementar pipelines de dados escal\u00e1veis e eficientes\nDesenvolver e manter arquiteturas de dados em nuvem (AWS, GCP, Azure)\nConstruir sistemas ETL/ELT para processamento de grandes volumes de dados\nImplementar solu\u00e7\u00f5es de streaming de dados em tempo real (Kafka, Kinesis)\nOtimizar performance de consultas e bancos de dados (SQL, NoSQL)\nColaborar com cientistas de dados e analistas na prepara\u00e7\u00e3o de dados\nImplementar pr\u00e1ticas de DataOps e versionamento de dados\nMonitorar e garantir qualidade dos dados atrav\u00e9s de testes automatizados\nDesenvolver APIs e microsservi\u00e7os para acesso aos dados\nDocumentar arquiteturas e processos de engenharia de dados\n", "prerequisites": "\nExperi\u00eancia comprovada como Data Engineer, Engenheiro de Dados ou fun\u00e7\u00e3o similar (3+ anos)\nDom\u00ednio avan\u00e7ado de Python e SQL para manipula\u00e7\u00e3o e transforma\u00e7\u00e3o de dados\nExperi\u00eancia com ferramentas de Big Data (Apache Spark, Hadoop, Airflow)\nConhecimento s\u00f3lido de bancos de dados relacionais e NoSQL (PostgreSQL, MongoDB, Redis)\nExperi\u00eancia pr\u00e1tica com plataformas de nuvem (AWS, GCP ou Azure)\nConhecimento de ferramentas de orquestra\u00e7\u00e3o (Apache Airflow, Prefect, Dagster)\nExperi\u00eancia com containeriza\u00e7\u00e3o (Docker, Kubernetes)\nConhecimento de versionamento de c\u00f3digo (Git) e metodologias \u00e1geis\nHabilidades de resolu\u00e7\u00e3o de problemas complexos e pensamento anal\u00edtico\nCapacidade de trabalhar com grandes volumes de dados e sistemas distribu\u00eddos\n", "differentials": "\nCertifica\u00e7\u00f5es em plataformas de nuvem (AWS Data Engineer, GCP Professional Data Engineer)\nExperi\u00eancia com ferramentas modernas de Data Stack (dbt, Snowflake, Databricks)\nConhecimento de Machine Learning e MLOps para deploy de modelos\nExperi\u00eancia com streaming de dados em tempo real (Apache Kafka, AWS Kinesis)\nConhecimento de Infrastructure as Code (Terraform, CloudFormation)\nExperi\u00eancia com Data Mesh e arquiteturas de dados modernas\nContribui\u00e7\u00f5es para projetos open source relacionados a dados\nConhecimento de linguagens complementares (Scala, Java, Go)\nExperi\u00eancia com ferramentas de observabilidade (Datadog, New Relic)\nExperi\u00eancia pr\u00e9via em startups ou empresas de tecnologia\nConhecimento de LGPD/GDPR e pr\u00e1ticas de governan\u00e7a de dados\n"}}}